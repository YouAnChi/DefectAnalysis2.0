# 缺陷分析系统详解

## 1. 系统概述

缺陷分析系统是一个基于大语言模型和向量检索技术的智能工具，旨在自动分析软件产品缺陷描述，并提供专业的缺陷分类、根因分析和改善策略建议。该系统通过Streamlit提供友好的Web界面，支持Excel文件上传、实时日志显示和结果下载等功能。

### 1.1 核心功能

- **智能分析**：利用大语言模型（DeepSeek）对缺陷进行智能分析
- **相似案例检索**：基于向量数据库（FAISS）进行相似案例检索
- **多评分分类支持**：根据不同评分分类（功能使用、体验良好、性能效率）选择不同的分析策略
- **批量处理**：支持Excel文件批量导入和处理
- **实时日志**：提供实时处理日志显示
- **结果导出**：支持分析结果和日志导出

### 1.2 系统架构

系统由以下主要组件构成：

1. **前端界面**：基于Streamlit构建的Web界面（`streamlit_app.py`）
2. **核心分析引擎**：基于LangChain和DeepSeek的分析模块（`app.py`）
3. **知识库**：包含历史缺陷案例的JSON文件（`defects_knowledge_base.json`）
4. **系统提示词**：针对不同评分分类的提示词文件（`sys.md`, `sys2.md`, `sys3.md`）
5. **数据处理模块**：提取和处理缺陷数据（`extract_defect_data.py`）
6. **可视化模块**：分析结果可视化（`visualization.py`）

## 2. 技术原理详解

### 2.1 向量检索技术

向量检索是系统的核心技术之一，它使系统能够从历史缺陷案例中找到与当前缺陷最相似的案例，为分析提供参考。

#### 2.1.1 工作原理

1. **文本向量化**：使用HuggingFace的text2vec-base-chinese模型将缺陷描述文本转换为高维向量
2. **向量索引构建**：使用FAISS（Facebook AI Similarity Search）库构建高效的向量索引
3. **相似度计算**：通过计算向量间的距离（通常是余弦相似度）来确定文本相似性

#### 2.1.2 代码实现

```python
# 初始化向量化模型
def init_embeddings():
    return HuggingFaceEmbeddings(model_name='shibing624/text2vec-base-chinese')

# 构建向量存储
def build_vector_store(_knowledge_base):
    defects = _knowledge_base['defects']
    texts = []
    metadatas = []
    
    for defect in defects:
        text = defect['defect_description']
        metadata = {
            'id': defect['id'],
            'defect_number': defect['defect_number'],
            # 其他元数据...
        }
        texts.append(text)
        metadatas.append(metadata)
    
    embeddings = init_embeddings()
    vector_store = FAISS.from_texts(texts, embeddings, metadatas=metadatas)
    return vector_store
```

### 2.2 大语言模型分析

系统使用DeepSeek大语言模型进行缺陷分析，通过精心设计的提示词引导模型生成专业的分析结果。

#### 2.2.1 工作原理

1. **模型初始化**：连接DeepSeek API并初始化模型
2. **提示词设计**：根据不同评分分类（功能使用、体验良好、性能效率）选择不同的系统提示词
3. **上下文构建**：将相似案例和当前缺陷描述组合成完整上下文
4. **流式生成**：使用流式API获取模型的分析结果

#### 2.2.2 代码实现

```python
# 初始化LLM模型
def init_llm():
    llm = ChatDeepSeek(
        model="deepseek-reasoner",
        api_key="your_api_key",
        base_url="https://api.deepseek.com",
    )
    return llm

# 分析缺陷
def analyze_defect(defect_description, defect_title, score_category, vector_store, llm):
    # 根据评分分类选择系统提示词文件
    system_prompt_file = 'sys.md'  # 默认
    if score_category == '体验良好':
        system_prompt_file = 'sys2.md'
    elif score_category == '性能效率':
        system_prompt_file = 'sys3.md'
    
    # 检索相似案例
    similar_docs = vector_store.similarity_search_with_score(defect_description, k=3)
    
    # 构建上下文
    context = "历史相似案例：\n"
    for i, (doc, score) in enumerate(similar_docs, 1):
        similarity = 100 / (1 + score)
        context += f"案例{i}（相似度: {similarity:.2f}%）：\n{doc.page_content}\n"
    
    # 加载系统提示词
    system_prompt = load_system_prompt(system_prompt_file)
    
    # 构建消息
    messages = [
        ("system", system_prompt),
        ("human", f"请基于以下历史案例分析当前缺陷：\n\n{context}\n当前缺陷标题：\n{defect_title}\n\n当前缺陷描述：\n{defect_description}\n\n评分分类：{score_category}")
    ]
    
    # 调用LLM进行分析
    reasoning_content = ""
    answer_content = ""
    for chunk in llm.stream(messages):
        if 'reasoning_content' in chunk.additional_kwargs:
            reasoning_content += chunk.additional_kwargs['reasoning_content']
        elif chunk.text():
            answer_content += chunk.text()
    
    return reasoning_content, answer_content
```

### 2.3 数据处理流程

系统的数据处理流程包括输入数据处理、分析结果提取和输出格式化。

#### 2.3.1 输入数据处理

1. **Excel文件读取**：读取包含缺陷描述的Excel文件
2. **数据验证**：检查必要字段（缺陷描述）是否存在
3. **数据预处理**：处理缺失值和格式化文本

#### 2.3.2 分析结果提取

系统使用正则表达式从LLM生成的文本中提取结构化信息：

```python
# 提取各个字段的数据
def extract_data_from_column(input_file, output_file):
    df = pd.read_excel(input_file)
    
    for index, row in df.iterrows():
        e_data = str(row[e_column_name])
        
        # 提取评分分类
        match = re.search(r'评分分类[：:](s*)([^\n]*)', e_data)
        if match:
            df.at[index, '评分分类'] = match.group(2).strip()
        
        # 提取严重等级
        match = re.search(r'严重等级[：:](s*)([^\n]*)', e_data)
        if match:
            df.at[index, '严重等级'] = match.group(2).strip()
        
        # 提取其他字段...
```

## 3. 系统组件详解

### 3.1 前端界面 (streamlit_app.py)

前端界面使用Streamlit框架构建，提供直观的用户交互体验。

#### 3.1.1 主要功能

- **文件上传**：支持Excel文件上传
- **参数设置**：允许用户设置分析参数
- **实时日志**：显示处理过程的实时日志
- **结果展示**：以表格形式展示分析结果
- **数据可视化**：提供分析结果的可视化图表
- **结果下载**：支持下载分析结果和日志

#### 3.1.2 实现细节

- 使用Streamlit的文件上传组件接收用户上传的Excel文件
- 使用多线程实现实时日志显示
- 使用队列（Queue）在线程间传递日志信息
- 使用临时文件存储中间结果

### 3.2 核心分析引擎 (app.py)

核心分析引擎负责缺陷分析的主要逻辑，包括向量检索、LLM调用和结果处理。

#### 3.2.1 主要功能

- **知识库加载**：加载历史缺陷案例
- **向量存储构建**：构建FAISS向量索引
- **相似案例检索**：检索相似的历史缺陷案例
- **LLM分析**：调用DeepSeek模型进行分析
- **批量处理**：处理Excel文件中的多条缺陷记录

#### 3.2.2 实现细节

- 使用tqdm添加进度条，提高用户体验
- 实现错误处理和日志记录，确保系统稳定性
- 支持不同评分分类的差异化处理

### 3.3 数据提取模块 (extract_defect_data.py)

数据提取模块负责从LLM生成的文本中提取结构化信息。

#### 3.3.1 主要功能

- **文本解析**：使用正则表达式解析LLM输出
- **数据结构化**：将解析结果转换为结构化数据
- **结果保存**：将结构化数据保存为Excel文件

#### 3.3.2 实现细节

- 使用正则表达式匹配不同字段
- 处理特殊情况和异常值
- 支持多种数据格式

### 3.4 可视化模块 (visualization.py)

可视化模块负责生成分析结果的可视化图表。

#### 3.4.1 主要功能

- **分类分布图**：展示评分分类分布
- **相似度直方图**：展示相似度分布
- **分析时间图**：展示分析时间分布
- **摘要指标**：展示关键统计指标

#### 3.4.2 实现细节

- 使用Plotly库创建交互式图表
- 设计美观的配色方案
- 优化图表布局和标签

## 4. 缺陷处理流程

### 4.1 完整处理流程

1. **数据输入**：用户上传包含缺陷描述的Excel文件
2. **数据预处理**：系统读取文件并验证数据格式
3. **知识库加载**：加载历史缺陷案例知识库
4. **向量索引构建**：构建FAISS向量索引
5. **批量处理**：对每条缺陷记录进行处理
   - **相似案例检索**：检索相似的历史缺陷案例
   - **上下文构建**：构建包含相似案例的上下文
   - **LLM分析**：调用DeepSeek模型进行分析
   - **结果解析**：解析LLM输出的分析结果
6. **结果汇总**：将所有分析结果汇总
7. **结果展示**：在界面上展示分析结果和可视化图表
8. **结果导出**：用户下载分析结果和日志

### 4.2 关键技术点

#### 4.2.1 相似案例检索优化

系统根据评分分类筛选知识库中的文档，提高检索精度：

```python
# 根据评分分类筛选文档
filtered_docs = []
for doc in all_docs:
    if doc.metadata.get('score_category') == score_category:
        filtered_docs.append(doc)

# 如果筛选后的文档数量太少，则使用原始检索
if len(filtered_docs) < 5:
    similar_docs = vector_store.similarity_search_with_score(defect_description, k=8)
else:
    # 创建临时向量存储用于检索
    temp_vector_store = FAISS.from_texts(
        [doc.page_content for doc in filtered_docs],
        embeddings,
        metadatas=[doc.metadata for doc in filtered_docs]
    )
    similar_docs = temp_vector_store.similarity_search_with_score(defect_description, k=8)
```

#### 4.2.2 提示词设计

系统根据不同评分分类使用不同的提示词文件，提高分析准确性：

- **功能使用**：使用`sys.md`提示词
- **体验良好**：使用`sys2.md`提示词
- **性能效率**：使用`sys3.md`提示词

每个提示词文件包含详细的分析标准和输出格式要求，引导LLM生成结构化的分析结果。

## 5. 实际应用案例

### 5.1 功能使用类缺陷分析

对于功能使用类缺陷，系统会分析缺陷的严重等级（1-5级）、缺陷类型（如功能性-功能适合性）、缺陷场景（如功能缺陷）、缺陷引入阶段（如需求阶段-需求错误）等，并提供详细的根因分析和改善策略。

### 5.2 体验良好类缺陷分析

对于体验良好类缺陷，系统会分析缺陷的严重等级（高/中/低）、缺陷类型（如易用性-交互流畅）、缺陷场景（如界面交互缺陷）等，并提供针对用户体验的改善建议。

### 5.3 性能效率类缺陷分析

对于性能效率类缺陷，系统会分析缺陷的严重等级、缺陷类型（如性能效率-时间特性）、缺陷场景（如性能缺陷）等，并提供针对性能优化的专业建议。

## 6. 系统扩展与优化

### 6.1 知识库扩展

可以通过不断添加新的缺陷案例来扩展知识库，提高系统的分析能力。知识库文件（`defects_knowledge_base.json`）使用JSON格式存储，便于更新和维护。

### 6.2 模型优化

可以尝试不同的大语言模型或向量化模型，以提高系统的分析准确性和效率。系统的模块化设计使得更换模型变得简单。

### 6.3 功能扩展

可以添加更多功能，如缺陷趋势分析、团队绩效分析等，进一步提高系统的实用性。

## 7. 总结

缺陷分析系统是一个结合了向量检索和大语言模型的智能工具，能够自动分析软件缺陷并提供专业的分析结果。系统的核心优势在于：

1. **智能分析**：利用大语言模型进行专业的缺陷分析
2. **相似案例检索**：基于向量检索找到相似的历史案例
3. **多评分分类支持**：针对不同类型的缺陷提供差异化分析
4. **用户友好界面**：提供直观的Web界面和实时日志
5. **结果可视化**：提供分析结果的可视化展示

通过学习本系统的实现，初级程序员可以了解向量检索、大语言模型应用、Web界面开发等多方面的知识，为开发类似的智能工具打下基础。